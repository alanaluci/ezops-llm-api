EzOps LLM API
API baseada em FastAPI e spaCy para Processamento de Linguagem Natural (NLP).


ğŸ“Œ Sobre o Projeto
A EzOps LLM API Ã© uma API de Processamento de Linguagem Natural que utiliza FastAPI e spaCy para responder perguntas e processar textos. AlÃ©m disso, ela possui integraÃ§Ã£o com ferramentas adicionais, como:

ğŸ“Š Calculadora â†’ Resolve expressÃµes matemÃ¡ticas.
ğŸ“š Pesquisa na Wikipedia â†’ Busca definiÃ§Ãµes e conceitos diretamente da Wikipedia.
O projeto foi desenvolvido para suportar inferÃªncia otimizada com PyTorch e Transformers da Hugging Face.

ğŸš€ Tecnologias Utilizadas
Python 3.12
FastAPI
Uvicorn
spaCy
Docker
Transformers (Hugging Face)
PyTorch

ğŸ“¦ Como Rodar o Projeto
1ï¸âƒ£ Clonar o RepositÃ³rio
git clone https://github.com/alanaluciaso/ezops-llm-api.git
cd ezops-llm-api
2ï¸âƒ£ Criar o Ambiente Virtual e Instalar DependÃªncias
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
pip install -r requirements.txt
3ï¸âƒ£ Baixar Modelo NLP (spaCy)
python -m spacy download pt_core_news_sm
4ï¸âƒ£ Rodar a API
uvicorn main:app --reload
A API estarÃ¡ disponÃ­vel em: http://127.0.0.1:8000

ğŸ›  Testando a API
ğŸ” Exemplo de RequisiÃ§Ã£o
Envie um JSON com um campo text:

json
{
  "text": "2 + 2"
}
ğŸ“Œ Resposta esperada
json
{
  "input": "2 + 2",
  "response": "Resultado da expressÃ£o matemÃ¡tica: 4",
  "tools_used": ["Calculator"]
}
âœ… Rodando os Testes
Usamos pytest para validar o funcionamento da API.

1ï¸âƒ£ Instalar pytest e httpx:
pip install pytest httpx
2ï¸âƒ£ Executar os testes:
pytest tests/
Se todos os testes passarem, significa que a API estÃ¡ funcionando corretamente! âœ…

ğŸ“¦ Rodando com Docker
Caso queira rodar a API dentro de um container Docker, siga os passos abaixo:

1ï¸âƒ£ Criar a imagem
docker build --no-cache --platform linux/aarch64 -t ezops-llm-api .
2ï¸âƒ£ Rodar o container
docker run -p 8000:8000 ezops-llm-api
A API estarÃ¡ disponÃ­vel em: http://127.0.0.1:8000

3ï¸âƒ£ Acessar a DocumentaÃ§Ã£o
Swagger UI: http://localhost:8000/docs
Redoc: http://localhost:8000/redoc

ğŸ”„ Endpoints DisponÃ­veis
ğŸ“Œ Health Check
http
GET /health
Resposta:
json
{ "status": "OK" }
ğŸ“Œ Processamento de Texto

POST /process
Body:
json
{ "text": "O spaCy Ã© uma biblioteca incrÃ­vel!" }
Resposta:
json
{
  "tokens": ["O", "spaCy", "Ã©", "uma", "biblioteca", "incrÃ­vel", "!"],
  "entities": []
}
ğŸ”§ SoluÃ§Ã£o de Problemas
âŒ Erro: "Bind for 0.0.0.0:8000 failed: port is already allocated"
âœ… SoluÃ§Ã£o: A porta 8000 jÃ¡ estÃ¡ em uso. Pare o processo que a estÃ¡ ocupando:


lsof -i :8000
kill -9 <PID>
Ou rode em outra porta:


docker run -p 8080:8000 ezops-llm-api
âŒ Erro: "No module named uvicorn"
âœ… SoluÃ§Ã£o: O uvicorn pode nÃ£o estar instalado corretamente dentro do container. Certifique-se de que estÃ¡ listado no requirements.txt.

âŒ Erro: "tarfile.ReadError: not a gzip file"
âœ… SoluÃ§Ã£o: O download do modelo do spaCy pode ter falhado. Tente remover e baixar novamente:
rm -rf /app/pt_core_news_sm.tar.gz
docker build --no-cache --platform linux/aarch64 -t ezops-llm-api .

ğŸ“œ LicenÃ§a
Este projeto Ã© open-source.

ğŸ‘©â€ğŸ’» Contribuindo
Sinta-se Ã  vontade para abrir Issues e Pull Requests para melhorias no projeto!

ğŸ“¬ Contato
ğŸ“Œ Desenvolvido por Alana Lucia Souza Oliveira.